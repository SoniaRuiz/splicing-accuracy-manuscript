---
title: "Creating a testing software for a database."
author: 
- name: "Sonia Garcia-Ruiz"
  affiliation: UCL
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  bookdown::html_document2:
    figure_caption: yes
    code_folding: show
    theme: paper
    highlight: kate
    df_print: paged
    toc: true
    toc_float: true
    number_sections: true
---

```{r setup, include = FALSE}

library(here) # For project-specific paths
library(tidyverse) # For tidy manipulation of data
library(stringr) # For string manipulation

knitr::opts_chunk$set(echo = T, warning = F, message = F)

# Set defaults for ggplots 
theme_rhr <- theme_set(
  theme_bw(base_family = "Helvetica",
           base_size = 10) + 
  theme(panel.grid.major.x = element_blank(),
        legend.position = "top",
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
        axis.title.y = element_text(vjust = 0.6),
        panel.spacing = unit(0.1, "lines"))
)

```


# Background

We need to create a testing framework for a SQLite database structure. Each database generated needs to meet some criteria to validate the integrity of the data it contains.

Creating a testing framework for the SQLite database structure we have already built, will help you understand how the type of data stored as well as how the different tables are related between them.

In the coming months, we would like you to build an SQLite database from the ENCODE data that you are currently generating as well as from other exon-exon junction data extracted from other projects. Therefore, I think that creating a unit test of the databases that already exist is not only necessary (as I do not currently have a testing framework to test them), but will also help you to set the basis for those future analyses.


# Methods {.tabset}

I have not explored the different testing softwares and libraries already offered by R, but I have seen that there are some packages that might fit with our testing purpose (PS: feel free to use the testing framework of your preference):

* [testthat package](https://bookdown.org/rdpeng/RProgDA/software-testing-framework-for-r-packages.html)
* [RUnit](https://cran.r-project.org/web/packages/RUnit/vignettes/RUnit.pdf)

As I am envisioning it, the testing framework should receive as input parameters (1) the path to the database, and (2) the path or paths to any other data dependencies. As output, it should generate a log file (e.g. .txt) with the result of the different tests performed. However, it might be better ways of doing it, feel free to find the best/most optimised option.


# Supplementary code {.tabset}

I have created in my AWS S3 a bucket named **'splicing-project'**, which contains a copy of my AWS R workspace:

* Everything you may need (code, results and data dependencies) can be found there.
* I will recommend you to focus in the (1) *"splicing-project/splicing-recount3-projects"*, which is the folder that contains different result files produced by the different R functions I use and (2) *"splicing-project-recount3/"*, which is the core repository for the databases and the R scripts I am also currently using.
* The databases are within the folder *"splicing-project-recount3/database/v105/"*. I will recommend you to start testing the databases from the folders **splicing/** and **introverse/old-copy/introverse.sqlite** as I think those are the more stable ones.
* I would recommend you to use the R scripts uploaded into my GitHub repo, as they are daily updated, whereas this copy on AWS will not.

The script **splicing-project-recount3/database/v105/database_testing.R** contains some testing and some data-integrity criteria that all databases should meet. At the end of the file, you can also find some desired TODO tests:

1. Test that all the data assigned to every junction and stored on the different columns matches with the original data. This includes:
- MaxEntScan scores
- Conservation/CDTS scores
- Read counts
- MANE info
- ClinVar data
- Intron type (i.e. u2_intron, u12_intron)

2. Check the overall integrity of the data:
- e.g. the number of introns in the child tables exactly matches with the introns in the parent table and same with the novel junctions

3. Check that when an intron is classified as never mis-spliced, it trully never mis-spliced (checking again with the original files and running a 'distances' function)

4. etc.

To get inspiration about the tests to run, I recommend you to read the paper of IntroVerse, which you can also find attached to the same email of this Rmarkdown document.

In addition, the file "init.R" within the directory **splicing-project-recount3/init.R**, is the source file that contains all the necessary functions that I am using to generate a database from scratch. I recommend you to have a look a it, just in case you are curious to know how I have generated the database.

Finally, you may also find useful other S3 buckets such as: **"data-references"** and **"encode-sirna-knockdown"**. The credentials to access my AWS S3 are attached to the email as well.


# Results 

Example of a function testing some functionality of the database **"splicing.sqlite"** and using some data dependencies:

```{r aws_connection, eval = F}

library(DBI)

gtf_version <- 105
main_project <- "splicing"
database_path <- paste0("~/PROJECTS/splicing-project-recount3/database/v",
                        gtf_version, "/", main_project, "/", main_project, ".sqlite")



#######################################
## Test that the read counts assigned to the intron "chr1:155214685-155215053:-" in the tissue "Adipose - Subcutaneous" as stored on IntroVerse, are correct when compared to the source data
#######################################

## Find in the original split read data whether the counts assigned for that annotated intron
## or novel junction whithin the database are the same within the original split read counts data

junID <- 'chr1:155214685-155215053:-'

tables <- dbListTables(con)
tables

project_id <- "ADIPOSE_TISSUE"
cluster_id <- "Adipose - Subcutaneous"
table_name <- paste0(cluster_id, "_", project_id, "_misspliced")
split_read_counts <- readRDS(file = paste0("/home/sruiz/PROJECTS/splicing-project/splicing-recount3-projects/", project_id, "/v",
                                           gtf_version, "/",
                                           main_project, "_project/raw_data/",
                                           project_id, "_", cluster_id, "_split_read_counts_sample_tidy.rds"))

if ( is.null(names(split_read_counts)) ) { 
  split_read_counts <- split_read_counts %>% 
    as_tibble(rownames = "junID")
}

#############

query = paste0("SELECT ref_junID, ref_coordinates FROM 'intron' WHERE ref_coordinates = '", junID, "'")
df_intron <- dbGetQuery(con, query) 
df_intron

query = paste0("SELECT * FROM '", table_name, "' WHERE ref_junID = ", paste0(df_intron$ref_junID))
df_missplicing <- dbGetQuery(con, query) 
df_missplicing

query = paste0("SELECT novel_junID, novel_coordinates FROM 'novel' WHERE novel_junID IN (", 
               paste(df_missplicing$novel_junID, collapse = ","), ")")
df_novel <- dbGetQuery(con, query) 
df_novel

df_merged <- merge(x = df_missplicing,
                   y = df_novel,
                   by = "novel_junID")

df_merged <- df_merged %>%
  inner_join(y = df_intron,
             by = c("ref_junID"))


original_counts_ref_junID <- split_read_counts %>%
  dplyr::filter(junID == (df_merged$ref_coordinates %>% unique())) %>%
  mutate(sum = rowSums(across(where(is.numeric)))) %>%
  dplyr::select(junID, sum)

if ((df_merged$ref_sum_counts %>% unique()) != original_counts_ref_junID$sum) {
  print(paste0("ERROR! The number of counts stored on IntroVerse for the intron '", 
               junID, "' differ from the original figure."))
}


## Test the read counts with the novel junction table
original_counts_novel_junID <- split_read_counts %>%
  dplyr::filter(junID == (df_merged$novel_coordinates[1])) %>%
  mutate(sum = rowSums(across(where(is.numeric)))) %>%
  dplyr::select(junID, sum)

## Ideally, this should be tested for all the novel junctions.
if ((df_merged$novel_sum_counts[1] %>% unique()) != original_counts_novel_junID$sum) {
  print(paste0("ERROR! The number of counts stored on IntroVerse for the first novel junction attached to the intron '", 
               junID, "' differ from the original figure."))
}


```



# Conclusions

This document contains the basic information required to start the thinking required to build a testing framework for a database.

# Next steps

Continue working on the ENSEMBL loop to analyse the splicing noise across the rest of RBPs. The full dataset of RBPs that we are interested in are the ones published in 2020 by *Van Nostrand et al.* [A Large-Scale Binding and Functional Map of Human RNA Binding Proteins](https://www.nature.com/articles/s41586-020-2077-3). You can find the list of RBPs attached in the same email that this Rmarkdown.

If you have time, it would be good if you could start thinking/designing a testing framework to test the **"splicing"** and **"introverse"** databases mentioned in the section "Supplementary code". 

# Session info

<details>
  <summary>Show/hide</summary>

```{r reproducibility, echo = FALSE}
# Session info
library("sessioninfo")
options(width = 120)
session_info()
```

</details> 
